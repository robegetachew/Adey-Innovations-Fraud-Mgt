{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "# Append the parent directory to sys.path\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# ignore warrning message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_development import ModelPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed datasets\n",
    "fraud_data = pd.read_csv('../data/proccessed_fraud_data.csv')\n",
    "credit_data = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>ip_int</th>\n",
       "      <th>country</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>...</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>transaction_frequency</th>\n",
       "      <th>average_velocity</th>\n",
       "      <th>source_Direct</th>\n",
       "      <th>source_SEO</th>\n",
       "      <th>browser_FireFox</th>\n",
       "      <th>browser_IE</th>\n",
       "      <th>browser_Opera</th>\n",
       "      <th>browser_Safari</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-11 03:47:13</td>\n",
       "      <td>2015-02-21 10:03:37</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>FGBQNDNBETFJJ</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>880217484</td>\n",
       "      <td>United States</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-06-02 16:40:57</td>\n",
       "      <td>2015-09-26 21:32:16</td>\n",
       "      <td>0.220690</td>\n",
       "      <td>MKFUIVOHLJBYN</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0</td>\n",
       "      <td>2785906106</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2015-05-28 07:53:06</td>\n",
       "      <td>2015-08-13 11:53:07</td>\n",
       "      <td>0.262069</td>\n",
       "      <td>SCQGQALXBUQZJ</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>356056736</td>\n",
       "      <td>United States</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2015-01-10 06:25:12</td>\n",
       "      <td>2015-03-04 20:56:37</td>\n",
       "      <td>0.179310</td>\n",
       "      <td>MSNWCFEHKTIOY</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0</td>\n",
       "      <td>2985180352</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2015-02-03 13:48:23</td>\n",
       "      <td>2015-03-12 12:46:23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>FROZWSSWOHZBE</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>578312545</td>\n",
       "      <td>United States</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0        2  2015-01-11 03:47:13  2015-02-21 10:03:37        0.310345   \n",
       "1        4  2015-06-02 16:40:57  2015-09-26 21:32:16        0.220690   \n",
       "2        8  2015-05-28 07:53:06  2015-08-13 11:53:07        0.262069   \n",
       "3       12  2015-01-10 06:25:12  2015-03-04 20:56:37        0.179310   \n",
       "4       16  2015-02-03 13:48:23  2015-03-12 12:46:23        0.000000   \n",
       "\n",
       "       device_id       age  class      ip_int        country  hour_of_day  \\\n",
       "0  FGBQNDNBETFJJ  0.120690      0   880217484  United States           10   \n",
       "1  MKFUIVOHLJBYN  0.344828      0  2785906106    Switzerland           21   \n",
       "2  SCQGQALXBUQZJ  0.120690      0   356056736  United States           11   \n",
       "3  MSNWCFEHKTIOY  0.017241      0  2985180352         Mexico           20   \n",
       "4  FROZWSSWOHZBE  0.241379      0   578312545  United States           12   \n",
       "\n",
       "   ...  time_diff  transaction_frequency  average_velocity  source_Direct  \\\n",
       "0  ...        0.0                      1               0.0              0   \n",
       "1  ...        0.0                      1               0.0              1   \n",
       "2  ...        0.0                      1               0.0              0   \n",
       "3  ...        0.0                      1               0.0              0   \n",
       "4  ...        0.0                      1               0.0              1   \n",
       "\n",
       "   source_SEO  browser_FireFox  browser_IE  browser_Opera  browser_Safari  \\\n",
       "0           1                0           0              0               0   \n",
       "1           0                0           0              0               1   \n",
       "2           1                0           0              0               0   \n",
       "3           0                0           0              0               1   \n",
       "4           0                0           1              0               0   \n",
       "\n",
       "   sex_M  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of the data\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.transaction_frequency.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "fraud_data = fraud_data.drop(['user_id', 'device_id', 'transaction_frequency','time_diff','average_velocity', 'ip_int', 'signup_time', 'purchase_time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Encoding\n",
    "In this method, I replace each category with its frequency in the fraud dataset. This can help maintain some information about the category without expanding the feature space too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding Example\n",
    "frequency = fraud_data['country'].value_counts()\n",
    "fraud_data['country_encoded'] = fraud_data['country'].map(frequency)\n",
    "\n",
    "# Drop the original 'country' column\n",
    "fraud_data = fraud_data.drop('country', axis=1)\n",
    "\n",
    "# scale 'country_encoded' column\n",
    "scaler = MinMaxScaler()\n",
    "fraud_data['country_encoded'] = scaler.fit_transform(fraud_data[['country_encoded']])[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data.to_csv('../data/final_preprocessed_fraud_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>source_Direct</th>\n",
       "      <th>source_SEO</th>\n",
       "      <th>browser_FireFox</th>\n",
       "      <th>browser_IE</th>\n",
       "      <th>browser_Opera</th>\n",
       "      <th>browser_Safari</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>country_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220690</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.262069</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.179310</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129141</th>\n",
       "      <td>0.503448</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129142</th>\n",
       "      <td>0.075862</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129143</th>\n",
       "      <td>0.165517</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129144</th>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129145</th>\n",
       "      <td>0.337931</td>\n",
       "      <td>0.120690</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129146 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        purchase_value       age  class  hour_of_day  day_of_week  \\\n",
       "0             0.310345  0.120690      0           10            5   \n",
       "1             0.220690  0.344828      0           21            5   \n",
       "2             0.262069  0.120690      0           11            3   \n",
       "3             0.179310  0.017241      0           20            2   \n",
       "4             0.000000  0.241379      0           12            3   \n",
       "...                ...       ...    ...          ...          ...   \n",
       "129141        0.503448  0.706897      0            7            2   \n",
       "129142        0.075862  0.327586      0            7            3   \n",
       "129143        0.165517  0.293103      0           23            4   \n",
       "129144        0.393103  0.517241      0           20            2   \n",
       "129145        0.337931  0.120690      1            6            0   \n",
       "\n",
       "        source_Direct  source_SEO  browser_FireFox  browser_IE  browser_Opera  \\\n",
       "0                   0           1                0           0              0   \n",
       "1                   1           0                0           0              0   \n",
       "2                   0           1                0           0              0   \n",
       "3                   0           0                0           0              0   \n",
       "4                   1           0                0           1              0   \n",
       "...               ...         ...              ...         ...            ...   \n",
       "129141              1           0                0           0              0   \n",
       "129142              1           0                0           1              0   \n",
       "129143              1           0                1           0              0   \n",
       "129144              1           0                0           0              0   \n",
       "129145              0           0                0           0              0   \n",
       "\n",
       "        browser_Safari  sex_M  country_encoded  \n",
       "0                    0      0         1.000000  \n",
       "1                    1      0         0.013506  \n",
       "2                    0      1         1.000000  \n",
       "3                    1      1         0.019294  \n",
       "4                    0      1         1.000000  \n",
       "...                ...    ...              ...  \n",
       "129141               1      1         0.054438  \n",
       "129142               0      0         0.062793  \n",
       "129143               0      0         0.125844  \n",
       "129144               0      1         1.000000  \n",
       "129145               0      1         1.000000  \n",
       "\n",
       "[129146 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development for Fraud_detaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/11 17:51:43 INFO mlflow.tracking.fluent: Experiment with name 'Fraud_Detection_Experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Example usage for fraud dataset:\n",
    "fraud_data_file_path = '../data/final_preprocessed_fraud_data.csv'\n",
    "fraud_pipeline = ModelPipeline('fraud', fraud_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:51:43,060 - INFO - Loading fraud data from ../data/final_preprocessed_fraud_data.csv...\n",
      "2025-02-11 17:51:43,292 - INFO - Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "# load data for model development\n",
    "fraud_pipeline.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:51:43,323 - INFO - Data has been split into train and test sets.\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and testing split \n",
    "fraud_pipeline.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:51:43,336 - INFO - Applying SMOTE to the training data...\n",
      "2025-02-11 17:51:43,691 - INFO - SMOTE applied to training data. Classes have been balanced.\n"
     ]
    }
   ],
   "source": [
    "# applay SMOTE oversampling for fraud data to fix the class inbalance\n",
    "fraud_pipeline.apply_smote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and Label Models for Fraud Detection Comparison\n",
    "models = [\n",
    "            (LogisticRegression(), 'Logistic Regression'),\n",
    "            (DecisionTreeClassifier(), 'Decision Tree'),\n",
    "            (RandomForestClassifier(), 'Random Forest'),\n",
    "            (GradientBoostingClassifier(), 'Gradient Boosting'),\n",
    "            (MLPClassifier(), 'MLP')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:51:43,732 - INFO - Training Logistic Regression on fraud dataset...\n",
      "2025-02-11 17:51:46,609 - INFO - Logistic Regression training complete.\n",
      "2025-02-11 17:51:46,620 - INFO - Evaluating Logistic Regression on fraud dataset...\n",
      "2025-02-11 17:51:46,669 - INFO - Logistic Regression evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.72     23389\n",
      "           1       0.10      0.42      0.16      2441\n",
      "\n",
      "    accuracy                           0.58     25830\n",
      "   macro avg       0.50      0.51      0.44     25830\n",
      "weighted avg       0.83      0.58      0.67     25830\n",
      "\n",
      "2025-02-11 17:51:46,670 - INFO - Logging Logistic Regression to MLflow...\n",
      "\u001b[31m2025/02/11 17:51:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:51:52,662 - INFO - Logistic Regression has been logged and saved in MLflow as version 4.\n",
      "2025-02-11 17:51:52,665 - INFO - Training Decision Tree on fraud dataset...\n",
      "2025-02-11 17:51:53,930 - INFO - Decision Tree training complete.\n",
      "2025-02-11 17:51:53,931 - INFO - Evaluating Decision Tree on fraud dataset...\n",
      "2025-02-11 17:51:53,955 - INFO - Decision Tree evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94     23389\n",
      "           1       0.43      0.59      0.50      2441\n",
      "\n",
      "    accuracy                           0.89     25830\n",
      "   macro avg       0.69      0.75      0.72     25830\n",
      "weighted avg       0.91      0.89      0.90     25830\n",
      "\n",
      "2025-02-11 17:51:53,956 - INFO - Logging Decision Tree to MLflow...\n",
      "\u001b[31m2025/02/11 17:51:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:51:59,380 - INFO - Decision Tree has been logged and saved in MLflow as version 3.\n",
      "2025-02-11 17:51:59,381 - INFO - Training Random Forest on fraud dataset...\n",
      "2025-02-11 17:52:26,188 - INFO - Random Forest training complete.\n",
      "2025-02-11 17:52:26,189 - INFO - Evaluating Random Forest on fraud dataset...\n",
      "2025-02-11 17:52:26,927 - INFO - Random Forest evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     23389\n",
      "           1       0.77      0.55      0.65      2441\n",
      "\n",
      "    accuracy                           0.94     25830\n",
      "   macro avg       0.86      0.77      0.81     25830\n",
      "weighted avg       0.94      0.94      0.94     25830\n",
      "\n",
      "2025-02-11 17:52:26,928 - INFO - Logging Random Forest to MLflow...\n",
      "\u001b[31m2025/02/11 17:52:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:52:34,379 - INFO - Random Forest has been logged and saved in MLflow as version 3.\n",
      "2025-02-11 17:52:34,383 - INFO - Training Gradient Boosting on fraud dataset...\n",
      "2025-02-11 17:52:53,132 - INFO - Gradient Boosting training complete.\n",
      "2025-02-11 17:52:53,132 - INFO - Evaluating Gradient Boosting on fraud dataset...\n",
      "2025-02-11 17:52:53,178 - INFO - Gradient Boosting evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86     23389\n",
      "           1       0.14      0.30      0.19      2441\n",
      "\n",
      "    accuracy                           0.76     25830\n",
      "   macro avg       0.53      0.55      0.52     25830\n",
      "weighted avg       0.84      0.76      0.79     25830\n",
      "\n",
      "2025-02-11 17:52:53,179 - INFO - Logging Gradient Boosting to MLflow...\n",
      "\u001b[31m2025/02/11 17:52:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:52:58,777 - INFO - Gradient Boosting has been logged and saved in MLflow as version 3.\n",
      "2025-02-11 17:52:58,778 - INFO - Training MLP on fraud dataset...\n",
      "2025-02-11 17:54:08,290 - INFO - MLP training complete.\n",
      "2025-02-11 17:54:08,291 - INFO - Evaluating MLP on fraud dataset...\n",
      "2025-02-11 17:54:08,344 - INFO - MLP evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.60      0.73     23389\n",
      "           1       0.14      0.65      0.24      2441\n",
      "\n",
      "    accuracy                           0.60     25830\n",
      "   macro avg       0.54      0.62      0.48     25830\n",
      "weighted avg       0.87      0.60      0.69     25830\n",
      "\n",
      "2025-02-11 17:54:08,346 - INFO - Logging MLP to MLflow...\n",
      "\u001b[31m2025/02/11 17:54:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:54:11,834 - INFO - MLP has been logged and saved in MLflow as version 3.\n"
     ]
    }
   ],
   "source": [
    "# Train, Evaluate, and Log Models for Fraud Detection Pipeline\n",
    "for model, name in models:\n",
    "            fraud_pipeline.train_model(model, name)\n",
    "            report = fraud_pipeline.evaluate_model(model, name)\n",
    "            fraud_pipeline.log_model(model, name, report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development for Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/11 17:54:11 INFO mlflow.tracking.fluent: Experiment with name 'creditcard_experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "#  model development for credit card\n",
    "creditcard_file_path = '../data/creditcard.csv'\n",
    "creditcard_pipeline = ModelPipeline('creditcard', creditcard_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:54:11,852 - INFO - Loading credit card data from ../data/creditcard.csv...\n",
      "2025-02-11 17:54:12,661 - INFO - Data loading complete.\n"
     ]
    }
   ],
   "source": [
    "# Load Credit Card Fraud Dataset for Processing\n",
    "creditcard_pipeline.load_data()  # Load and prepare data for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:54:12,715 - INFO - Data has been split into train and test sets.\n"
     ]
    }
   ],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "creditcard_pipeline.split_data()  # Divide dataset for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and Label Models for credit_card fraud Detection Comparison\n",
    "credit_models = [\n",
    "            (LogisticRegression(), 'Logistic Regression'),\n",
    "            (DecisionTreeClassifier(), 'Decision Tree'),\n",
    "            (RandomForestClassifier(), 'Random Forest'),\n",
    "            (GradientBoostingClassifier(), 'Gradient Boosting'),\n",
    "            (MLPClassifier(), 'Multi-Layer Perceptron')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:54:12,725 - INFO - Training Logistic Regression on creditcard dataset...\n",
      "2025-02-11 17:54:17,025 - INFO - Logistic Regression training complete.\n",
      "2025-02-11 17:54:17,030 - INFO - Evaluating Logistic Regression on creditcard dataset...\n",
      "2025-02-11 17:54:17,098 - INFO - Logistic Regression evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.62      0.57      0.59        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.81      0.79      0.80     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2025-02-11 17:54:17,099 - INFO - Logging Logistic Regression to MLflow...\n",
      "\u001b[31m2025/02/11 17:54:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:54:20,873 - INFO - Logistic Regression has been logged and saved in MLflow as version 2.\n",
      "2025-02-11 17:54:20,874 - INFO - Training Decision Tree on creditcard dataset...\n",
      "2025-02-11 17:54:37,539 - INFO - Decision Tree training complete.\n",
      "2025-02-11 17:54:37,539 - INFO - Evaluating Decision Tree on creditcard dataset...\n",
      "2025-02-11 17:54:37,557 - INFO - Decision Tree evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.71      0.78      0.74        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.85      0.89      0.87     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2025-02-11 17:54:37,558 - INFO - Logging Decision Tree to MLflow...\n",
      "\u001b[31m2025/02/11 17:54:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:54:41,485 - INFO - Decision Tree has been logged and saved in MLflow as version 2.\n",
      "2025-02-11 17:54:41,487 - INFO - Training Random Forest on creditcard dataset...\n",
      "2025-02-11 17:57:45,752 - INFO - Random Forest training complete.\n",
      "2025-02-11 17:57:45,753 - INFO - Evaluating Random Forest on creditcard dataset...\n",
      "2025-02-11 17:57:45,994 - INFO - Random Forest evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.97      0.80      0.88        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.90      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2025-02-11 17:57:45,995 - INFO - Logging Random Forest to MLflow...\n",
      "\u001b[31m2025/02/11 17:57:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 17:57:49,794 - INFO - Random Forest has been logged and saved in MLflow as version 2.\n",
      "2025-02-11 17:57:49,795 - INFO - Training Gradient Boosting on creditcard dataset...\n",
      "2025-02-11 18:03:07,830 - INFO - Gradient Boosting training complete.\n",
      "2025-02-11 18:03:07,831 - INFO - Evaluating Gradient Boosting on creditcard dataset...\n",
      "2025-02-11 18:03:07,874 - INFO - Gradient Boosting evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.74      0.60      0.66        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.80      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2025-02-11 18:03:07,875 - INFO - Logging Gradient Boosting to MLflow...\n",
      "\u001b[31m2025/02/11 18:03:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 18:03:12,035 - INFO - Gradient Boosting has been logged and saved in MLflow as version 2.\n",
      "2025-02-11 18:03:12,036 - INFO - Training Multi-Layer Perceptron on creditcard dataset...\n",
      "2025-02-11 18:04:28,162 - INFO - Multi-Layer Perceptron training complete.\n",
      "2025-02-11 18:04:28,162 - INFO - Evaluating Multi-Layer Perceptron on creditcard dataset...\n",
      "2025-02-11 18:04:28,986 - INFO - Multi-Layer Perceptron evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.65      0.76      0.70        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.83      0.88      0.85     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "2025-02-11 18:04:28,987 - INFO - Logging Multi-Layer Perceptron to MLflow...\n",
      "\u001b[31m2025/02/11 18:04:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025-02-11 18:04:33,457 - INFO - Multi-Layer Perceptron has been logged and saved in MLflow as version 2.\n"
     ]
    }
   ],
   "source": [
    "# Train, Evaluate, and Log Credit Card Fraud Models\n",
    "for model, name in credit_models:\n",
    "            creditcard_pipeline.train_model(model, name)\n",
    "            report = creditcard_pipeline.evaluate_model(model, name)\n",
    "            creditcard_pipeline.log_model(model, name, report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
